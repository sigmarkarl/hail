.. _sec-batch-service:

=============
Batch Service
=============


What is the Batch Service?
--------------------------

Instead of executing jobs on your local computer (the default in Pipeline), you can execute
your jobs on a multi-tenant compute cluster in Google Cloud that is managed by the Hail team
and is called Batch. Batch consists of a scheduler that receives job submission requests
from users and then executes jobs in Docker containers on Google Compute Engine VMs (workers)
that are shared amongst all Batch users. A UI is available at `<batch.hail.is>`_ that allows a
user to see job progress and access logs.


.. _file-localization:

File Localization
-----------------

A job is executed in three separate Docker containers: input, main, output. The input container
downloads files from google storage to the input container. These input files are either inputs
to the pipeline or are output files that have been generated by a dependent job. The downloaded
files are then passed on to the main container via a shared volume where the user's code is
executed. Finally, the output container runs and uploads any files from the shared volume that
have been specified to be uploaded by the user. These files can either be specified with
:meth:`.Pipeline.write_output` or are file dependencies for downstream jobs.


Service Accounts
----------------

A service account is automatically created for a new Batch user that is used by Batch to download data
on your behalf. This service account needs to be added to Google Storage buckets with your data and Docker
images under Permissions.


Billing
-------

The cost for executing a job depends on the underlying machine type and how much CPU and
memory is being requested. Currently, Batch runs all jobs on 16 core, preemptible, n1-standard
machines with 100 GB of disk total. The costs are as follows:

- Compute cost
   = $0.01 per core per hour

- Disk cost
   .. code-block:: text

       Average number of days per month = 365.25 / 12 = 30.4375

       Cost per GB per month = $0.17

       Cost per core per hour = $0.17 * 100 / 30.4375 / 24 / 16

   = $0.001454 per core per hour

- IP network cost
   = $0.00025 per core per hour

- Service cost
   = $0.01 per core per hour

The sum of these costs is **$0.02170** per core per hour.

.. note::

    The amount of CPU reserved for a job can be rounded up if the equivalent memory request
    requires a larger fraction of the worker. Currently, each 1 core requested
    gets 3.75 GB of memory. Therefore, if a user requests 1 CPU and 7 GB of memory, the user
    will get 2 cores for their job and will be billed for 2 cores.

.. note::

    If a worker is preempted by google in the middle of running a job, you will be billed for
    the time the job was running up until the preemption time. The job will be rescheduled on
    a different worker and run again. Therefore, if a job takes 5 minutes to run, but was preempted
    after running for 2 minutes and then runs successfully the next time it is scheduled, the
    total cost for that job will be 7 minutes.

.. note::

    You are billed only for the time in which your job is running. We do not bill for the time it
    takes to download input files, pull Docker images, upload log files, or upload output files.

Setup
-----

We assume you've already installed Pipeline as described in the
:ref:`Getting Started <sec-getting_started>` section and we have
created a user account for you and given you a billing project.

To authenticate your computer with the Batch service, run the following
command in a terminal window:

.. code-block:: sh

    hailctl auth login

Executing this command will take you to a login page in your browser window where
you can select your google account to authenticate with. If everything works successfully,
you should see a message "hailctl is now authenticated." in your browser window and no
error messages in the terminal window.

Submitting a Pipeline to Batch
------------------------------

To execute a pipeline on the Batch service rather than locally, first construct a
:class:`.BatchBackend` object with a valid billing project name. Next, pass the :class:`.BatchBackend`
object to the :class:`.Pipeline` constructor with the parameter name `backend`.

An example of running "Hello World" on the Batch service rather than locally is shown below.
You can open iPython or a Jupyter notebook and run the following pipeline:

.. code-block:: python

    >>> import hailtop.pipeline as hp
    >>> backend = hp.BatchBackend('test') # replace 'test' with your own billing project
    >>> p = hp.Pipeline(backend=backend, name='test')
    >>> t = p.new_task(name='hello')
    >>> t.command('echo "hello world"')
    >>> p.run(open=True)


Using the UI
------------

If you have submitted the pipeline above successfully, then it should open a page in your
browser with a UI page for the pipeline you submitted. This will show a list of all the jobs
in the batch with the current state, exit code, duration, and cost. The possible job states
are as follows:

- Pending - A job is waiting for its dependencies to complete
- Ready - All of a job's dependencies have completed, but the job has not been scheduled to run
- Running - A job has been scheduled to run on a worker
- Success - A job finished with exit code 0
- Failure - A job finished with exit code not equal to 0
- Error - The Docker container had an error (ex: out of memory)

Clicking on a specific job will take you to a page with the logs for each of the three containers
run per job (:ref:`see above <file-localization>`) as well as a copy of the job spec and detailed
information about the job such as where the job was run, how long it took to pull the image for
each container, and any error messages.

To see all batches you've submitted, go to `<batch.hail.is>`_. Each batch will have a current state,
number of jobs total, and the number of pending, succeeded, failed, and cancelled jobs as well as the
running cost of the batch (computed from completed jobs only). The possible batch states are as follows:

- open - Not all jobs in the batch have been successfully submitted.
- running - All jobs in the batch have been successfully submitted.
- success - All jobs in the batch have completed with state "Success"
- failure - Any job has completed with state "Failure" or "Error"
- cancelled - Any job has been cancelled and no jobs have completed with state "Failure" or "Error"

.. note::
    Jobs can still be running even if the batch has been marked as failure or cancelled. In the case of
    'failure', other jobs that do not depend on the failed job will still run. In the case of cancelled,
    it takes time to cancel a batch, especially for larger batches.

Individual jobs cannot be cancelled or deleted. Instead, you can cancel the entire batch with the "Cancel"
button next to the row for that batch. You can also delete a batch with the "Delete" button.

.. warning::

    Deleting a batch only removes it from the UI. You will still be billed for a deleted batch.
